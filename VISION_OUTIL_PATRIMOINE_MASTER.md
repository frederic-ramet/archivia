# Vision : Plateforme Patrimoniale Unifi√©e

## Executive Summary

Ce document d√©finit la vision d'une **plateforme open-source de num√©risation, analyse et valorisation du patrimoine** combinant le meilleur des projets Journal de Guerre (OCR + analyse s√©mantique) et Opale (pr√©sentation interactive + PWA). L'objectif est de cr√©er un outil g√©n√©rique, extensible et performant pour tout projet de pr√©servation patrimoniale.

**Nom propos√©** : `Archivia` - Archive Interactive et Visuelle avec Intelligence Artificielle

---

## 1. Synth√®se Comparative

### 1.1 Forces √† Combiner

| Capacit√© | Journal de Guerre | Opale | Solution Master |
|----------|------------------|-------|-----------------|
| **OCR Manuscrit** | ‚úÖ Multi-provider (Ollama/Claude) | ‚ùå | ‚úÖ Int√©gr√© + am√©lior√© |
| **Ontologie** | ‚úÖ Extraction automatique | ‚ö†Ô∏è Partiel | ‚úÖ Complet + √©ditable |
| **Recherche s√©mantique** | ‚úÖ Embeddings | ‚ö†Ô∏è Full-text basique | ‚úÖ Hybride vectoriel |
| **Frontend moderne** | ‚ùå EJS SSR | ‚úÖ Next.js 14 + React | ‚úÖ Next.js 15 + React 19 |
| **TypeScript** | ‚ùå JavaScript | ‚úÖ Strict mode | ‚úÖ Strict + schemas Zod |
| **PWA** | ‚ùå | ‚úÖ Complet | ‚úÖ Offline-first |
| **Hotspots** | ‚ùå | ‚úÖ 35KB composant | ‚úÖ + √©diteur visuel |
| **Mode narratif** | ‚ùå | ‚úÖ Stories | ‚úÖ + g√©n√©ration IA |
| **Timeline** | ‚ùå | ‚úÖ Interactive | ‚úÖ + filtres avanc√©s |
| **Annotations** | ‚ùå | ‚ùå | ‚úÖ Collaboratives |
| **API REST** | ‚ö†Ô∏è Basique | ‚ùå | ‚úÖ Compl√®te + GraphQL |
| **Multi-corpus** | ‚ùå Mono-projet | ‚ùå Mono-projet | ‚úÖ Multi-tenant |
| **Export** | ‚ùå | ‚ùå | ‚úÖ PDF, JSON-LD, BibTeX |

### 1.2 Architecture Cible - Les 3 Espaces

```
ARCHIVIA PLATFORM
‚îú‚îÄ‚îÄ üéØ CORE ENGINE (Backend)
‚îÇ   ‚îú‚îÄ‚îÄ API REST/GraphQL
‚îÇ   ‚îú‚îÄ‚îÄ Base de donn√©es relationnelle + vectorielle
‚îÇ   ‚îú‚îÄ‚îÄ Service OCR multi-provider
‚îÇ   ‚îú‚îÄ‚îÄ Service ontologie/NLP progressif
‚îÇ   ‚îú‚îÄ‚îÄ Service recherche hybride
‚îÇ   ‚îî‚îÄ‚îÄ Moteur de g√©n√©ration de contenu IA
‚îÇ
‚îú‚îÄ‚îÄ üîß WORKSPACE (Espace TRAVAIL sur l'archive)
‚îÇ   ‚îú‚îÄ‚îÄ Import et num√©risation
‚îÇ   ‚îú‚îÄ‚îÄ OCR et transcription
‚îÇ   ‚îú‚îÄ‚îÄ √âditeur d'annotations
‚îÇ   ‚îú‚îÄ‚îÄ Cr√©ateur de hotspots
‚îÇ   ‚îú‚îÄ‚îÄ Gestionnaire d'ontologie progressive
‚îÇ   ‚îú‚îÄ‚îÄ Validation et correction collaborative
‚îÇ   ‚îî‚îÄ‚îÄ G√©n√©ration de m√©tadonn√©es IA
‚îÇ
‚îú‚îÄ‚îÄ üìñ READER (Espace LECTURE de l'archive)
‚îÇ   ‚îú‚îÄ‚îÄ Galerie interactive
‚îÇ   ‚îú‚îÄ‚îÄ Mode histoire immersif
‚îÇ   ‚îú‚îÄ‚îÄ Navigation chronologique
‚îÇ   ‚îú‚îÄ‚îÄ Visualisation g√©ographique
‚îÇ   ‚îú‚îÄ‚îÄ Parcours th√©matiques
‚îÇ   ‚îî‚îÄ‚îÄ PWA offline
‚îÇ
‚îú‚îÄ‚îÄ üß† INSIGHT (Espace COMPR√âHENSION de l'archive)
‚îÇ   ‚îú‚îÄ‚îÄ Analyse s√©mantique profonde
‚îÇ   ‚îú‚îÄ‚îÄ Graphe de connaissances interactif
‚îÇ   ‚îú‚îÄ‚îÄ Moteur de questions/r√©ponses IA
‚îÇ   ‚îú‚îÄ‚îÄ G√©n√©ration de synth√®ses automatiques
‚îÇ   ‚îú‚îÄ‚îÄ D√©tection de patterns et tendances
‚îÇ   ‚îú‚îÄ‚îÄ Recommandations intelligentes
‚îÇ   ‚îî‚îÄ‚îÄ Exports analytiques
‚îÇ
‚îî‚îÄ‚îÄ üîå EXTENSIONS
    ‚îú‚îÄ‚îÄ Plugins d'import (TIFF, PDF, etc.)
    ‚îú‚îÄ‚îÄ Connecteurs IA (Ollama, Claude, GPT)
    ‚îú‚îÄ‚îÄ Exports (PDF, IIIF, JSON-LD)
    ‚îî‚îÄ‚îÄ Int√©grations (Notion, Airtable)
```

### 1.3 Philosophie des 3 Espaces

| Espace | Objectif | Utilisateurs | Actions Cl√©s |
|--------|----------|--------------|--------------|
| **WORKSPACE** | Construire et enrichir l'archive | Chercheurs, archivistes | Importer, transcrire, annoter, valider |
| **READER** | Consulter et naviguer l'archive | Grand public, √©tudiants | Explorer, lire, visualiser, partager |
| **INSIGHT** | Comprendre et analyser l'archive | Analystes, historiens | Questionner, synth√©tiser, d√©couvrir, exporter |

---

## 2. Sp√©cifications Techniques D√©taill√©es

### 2.1 Stack Technologique Recommand√©

| Couche | Technologie | Justification |
|--------|-------------|---------------|
| **Framework** | Next.js 15 (App Router) | SSR/SSG/ISR + Edge Runtime |
| **UI** | React 19 + Server Components | Performance maximale |
| **Typage** | TypeScript 5.4+ strict | Robustesse code |
| **Validation** | Zod | Schemas runtime + types |
| **State** | Zustand + React Query | L√©ger + cache intelligent |
| **Styling** | Tailwind CSS 4.0 | Design system coh√©rent |
| **Animation** | Framer Motion 12 | UX fluide |
| **Base donn√©es** | PostgreSQL + pgvector | Relationnel + vectoriel |
| **ORM** | Drizzle ORM | Type-safe, performant |
| **Auth** | NextAuth.js v5 | Multi-provider |
| **Storage** | S3/R2 | Images haute r√©solution |
| **Cache** | Redis | Session + requ√™tes |
| **Search** | Meilisearch | Full-text rapide |
| **Vectors** | pgvector | Embeddings s√©mantiques |
| **Queue** | BullMQ | Jobs asynchrones (OCR) |
| **OCR** | Tesseract + Claude/Ollama | Multi-engine |
| **NLP** | spaCy + sentence-transformers | FR/EN support |
| **PWA** | Workbox | Service Worker avanc√© |
| **Deploy** | Vercel/Railway + Docker | Scalable |

### 2.2 Structure du Projet

```
archivia/
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îú‚îÄ‚îÄ web/                    # Application principale Next.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ (auth)/         # Routes authentifi√©es
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ studio/     # Interface d'√©dition
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dashboard/  # Tableau de bord
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ (public)/       # Routes publiques
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gallery/    # Galerie interactive
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ story/      # Mode narratif
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search/     # Recherche avanc√©e
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ timeline/   # Frise chronologique
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ map/        # Visualisation g√©o
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/            # API Routes
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ documents/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ annotations/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ontology/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ai/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ layout.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ui/             # Composants de base
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gallery/        # Galerie
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ editor/         # √âditeurs
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ annotations/    # Annotations
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ontology/       # Graphe
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ story/          # Narratif
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ db/             # Drizzle schemas
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ai/             # Services IA
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search/         # Moteur recherche
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ hooks/              # React hooks custom
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ workers/                # Services background
‚îÇ       ‚îú‚îÄ‚îÄ ocr-worker/         # Extraction texte
‚îÇ       ‚îú‚îÄ‚îÄ embedding-worker/   # G√©n√©ration vecteurs
‚îÇ       ‚îî‚îÄ‚îÄ export-worker/      # G√©n√©ration exports
‚îÇ
‚îú‚îÄ‚îÄ packages/
‚îÇ   ‚îú‚îÄ‚îÄ database/               # Schemas Drizzle partag√©s
‚îÇ   ‚îú‚îÄ‚îÄ ai-services/            # Abstraction providers IA
‚îÇ   ‚îú‚îÄ‚îÄ ontology-engine/        # Moteur ontologique
‚îÇ   ‚îú‚îÄ‚îÄ search-engine/          # Moteur recherche hybride
‚îÇ   ‚îî‚îÄ‚îÄ shared-types/           # Types TypeScript partag√©s
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ seed-db.ts              # Donn√©es initiales
‚îÇ   ‚îú‚îÄ‚îÄ migrate.ts              # Migrations DB
‚îÇ   ‚îî‚îÄ‚îÄ import-legacy.ts        # Import depuis anciens projets
‚îÇ
‚îî‚îÄ‚îÄ docs/
    ‚îú‚îÄ‚îÄ api/                    # Documentation API
    ‚îú‚îÄ‚îÄ guides/                 # Tutoriels utilisateurs
    ‚îî‚îÄ‚îÄ architecture/           # Documentation technique
```

### 2.3 Sch√©ma de Base de Donn√©es

```sql
-- Core entities
CREATE TABLE projects (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  name VARCHAR(255) NOT NULL,
  slug VARCHAR(255) UNIQUE NOT NULL,
  description TEXT,
  config JSONB DEFAULT '{}',
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE TABLE documents (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  project_id UUID REFERENCES projects(id) ON DELETE CASCADE,
  type VARCHAR(50) NOT NULL, -- 'image', 'manuscript', 'printed', 'mixed'
  title VARCHAR(255) NOT NULL,
  file_path VARCHAR(500) NOT NULL,
  thumbnail_path VARCHAR(500),
  metadata JSONB DEFAULT '{}',
  -- Champs h√©rit√©s de Journal de Guerre
  transcription TEXT,
  transcription_status VARCHAR(50) DEFAULT 'pending', -- 'pending', 'processing', 'completed', 'verified'
  transcription_provider VARCHAR(50), -- 'ollama', 'claude', 'manual'
  -- Champs h√©rit√©s d'Opale
  category VARCHAR(100),
  period VARCHAR(100),
  tags TEXT[] DEFAULT '{}',
  historical_context TEXT,
  -- Recherche
  search_vector tsvector,
  embedding vector(384), -- sentence-transformers
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_documents_search ON documents USING gin(search_vector);
CREATE INDEX idx_documents_embedding ON documents USING ivfflat (embedding vector_cosine_ops);

-- Annotations (nouveau)
CREATE TABLE annotations (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  document_id UUID REFERENCES documents(id) ON DELETE CASCADE,
  user_id UUID REFERENCES users(id),
  type VARCHAR(50) NOT NULL, -- 'note', 'correction', 'hotspot', 'region'
  content TEXT,
  -- Coordonn√©es pour hotspots/r√©gions
  x DECIMAL,
  y DECIMAL,
  width DECIMAL,
  height DECIMAL,
  -- M√©tadonn√©es
  metadata JSONB DEFAULT '{}',
  status VARCHAR(50) DEFAULT 'draft', -- 'draft', 'published', 'archived'
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Ontologie (h√©rit√© de Journal de Guerre, am√©lior√©)
CREATE TABLE entities (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  project_id UUID REFERENCES projects(id) ON DELETE CASCADE,
  type VARCHAR(100) NOT NULL, -- 'person', 'place', 'concept', 'object', 'event'
  name VARCHAR(255) NOT NULL,
  aliases TEXT[] DEFAULT '{}',
  description TEXT,
  properties JSONB DEFAULT '{}',
  embedding vector(384),
  created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE TABLE entity_relationships (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  source_id UUID REFERENCES entities(id) ON DELETE CASCADE,
  target_id UUID REFERENCES entities(id) ON DELETE CASCADE,
  relation_type VARCHAR(100) NOT NULL, -- 'is_part_of', 'created_by', 'located_in', etc.
  properties JSONB DEFAULT '{}',
  weight DECIMAL DEFAULT 1.0,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE TABLE document_entities (
  document_id UUID REFERENCES documents(id) ON DELETE CASCADE,
  entity_id UUID REFERENCES entities(id) ON DELETE CASCADE,
  mention_count INTEGER DEFAULT 1,
  confidence DECIMAL DEFAULT 1.0,
  contexts JSONB DEFAULT '[]', -- positions dans le texte
  PRIMARY KEY (document_id, entity_id)
);

-- Hotspots (h√©rit√© d'Opale)
CREATE TABLE hotspots (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  document_id UUID REFERENCES documents(id) ON DELETE CASCADE,
  entity_id UUID REFERENCES entities(id),
  x DECIMAL NOT NULL,
  y DECIMAL NOT NULL,
  radius DECIMAL DEFAULT 5,
  label VARCHAR(255),
  color VARCHAR(20) DEFAULT '#3B82F6',
  metadata JSONB DEFAULT '{}',
  created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE TABLE hotspot_relations (
  hotspot_id UUID REFERENCES hotspots(id) ON DELETE CASCADE,
  related_document_id UUID REFERENCES documents(id) ON DELETE CASCADE,
  similarity_score DECIMAL DEFAULT 0.5,
  relation_type VARCHAR(100),
  PRIMARY KEY (hotspot_id, related_document_id)
);

-- Contextes historiques (h√©rit√© d'Opale)
CREATE TABLE historical_contexts (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  project_id UUID REFERENCES projects(id) ON DELETE CASCADE,
  name VARCHAR(255) NOT NULL,
  period_start DATE,
  period_end DATE,
  description TEXT,
  content JSONB DEFAULT '{}',
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Stories/Narratifs (h√©rit√© d'Opale)
CREATE TABLE stories (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  project_id UUID REFERENCES projects(id) ON DELETE CASCADE,
  title VARCHAR(255) NOT NULL,
  description TEXT,
  cover_image_id UUID REFERENCES documents(id),
  content JSONB DEFAULT '[]', -- S√©quence d'√©l√©ments
  published BOOLEAN DEFAULT FALSE,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Utilisateurs et permissions
CREATE TABLE users (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  email VARCHAR(255) UNIQUE NOT NULL,
  name VARCHAR(255),
  role VARCHAR(50) DEFAULT 'viewer', -- 'admin', 'editor', 'contributor', 'viewer'
  created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE TABLE project_members (
  project_id UUID REFERENCES projects(id) ON DELETE CASCADE,
  user_id UUID REFERENCES users(id) ON DELETE CASCADE,
  role VARCHAR(50) DEFAULT 'viewer',
  PRIMARY KEY (project_id, user_id)
);

-- Jobs asynchrones (OCR, embeddings, exports)
CREATE TABLE jobs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  type VARCHAR(100) NOT NULL, -- 'ocr', 'embedding', 'export', 'entity_extraction'
  status VARCHAR(50) DEFAULT 'pending',
  payload JSONB DEFAULT '{}',
  result JSONB DEFAULT '{}',
  error TEXT,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  started_at TIMESTAMPTZ,
  completed_at TIMESTAMPTZ
);
```

### 2.4 API REST Specification

```typescript
// Types principaux (packages/shared-types)
import { z } from 'zod';

export const DocumentSchema = z.object({
  id: z.string().uuid(),
  projectId: z.string().uuid(),
  type: z.enum(['image', 'manuscript', 'printed', 'mixed']),
  title: z.string().min(1),
  filePath: z.string(),
  thumbnailPath: z.string().optional(),
  transcription: z.string().optional(),
  transcriptionStatus: z.enum(['pending', 'processing', 'completed', 'verified']),
  category: z.string().optional(),
  period: z.string().optional(),
  tags: z.array(z.string()),
  historicalContext: z.string().optional(),
  metadata: z.record(z.unknown()),
  createdAt: z.date(),
  updatedAt: z.date(),
});

export const AnnotationSchema = z.object({
  id: z.string().uuid(),
  documentId: z.string().uuid(),
  userId: z.string().uuid(),
  type: z.enum(['note', 'correction', 'hotspot', 'region']),
  content: z.string(),
  x: z.number().optional(),
  y: z.number().optional(),
  width: z.number().optional(),
  height: z.number().optional(),
  metadata: z.record(z.unknown()),
  status: z.enum(['draft', 'published', 'archived']),
  createdAt: z.date(),
});

export const SearchQuerySchema = z.object({
  query: z.string().min(1),
  projectId: z.string().uuid().optional(),
  filters: z.object({
    types: z.array(z.string()).optional(),
    categories: z.array(z.string()).optional(),
    periods: z.array(z.string()).optional(),
    tags: z.array(z.string()).optional(),
    dateRange: z.object({
      start: z.date().optional(),
      end: z.date().optional(),
    }).optional(),
  }).optional(),
  mode: z.enum(['text', 'semantic', 'hybrid']).default('hybrid'),
  limit: z.number().min(1).max(100).default(20),
  offset: z.number().min(0).default(0),
});

// API Endpoints (apps/web/app/api/)

// Documents
GET    /api/projects/:projectId/documents
POST   /api/projects/:projectId/documents
GET    /api/documents/:id
PUT    /api/documents/:id
DELETE /api/documents/:id
POST   /api/documents/:id/transcribe      // Lancer OCR
POST   /api/documents/:id/generate-embedding
GET    /api/documents/:id/similar

// Annotations
GET    /api/documents/:id/annotations
POST   /api/documents/:id/annotations
PUT    /api/annotations/:id
DELETE /api/annotations/:id

// Hotspots
GET    /api/documents/:id/hotspots
POST   /api/documents/:id/hotspots
PUT    /api/hotspots/:id
DELETE /api/hotspots/:id
GET    /api/hotspots/:id/related

// Ontologie
GET    /api/projects/:projectId/entities
POST   /api/projects/:projectId/entities
GET    /api/entities/:id
PUT    /api/entities/:id
DELETE /api/entities/:id
GET    /api/entities/:id/relationships
POST   /api/entities/:id/relationships
GET    /api/documents/:id/entities        // Entit√©s mentionn√©es
POST   /api/documents/:id/extract-entities // NLP automatique

// Recherche
POST   /api/search                        // Recherche hybride
GET    /api/search/suggestions            // Auto-complete
POST   /api/search/semantic               // Requ√™te vectorielle pure

// Stories
GET    /api/projects/:projectId/stories
POST   /api/projects/:projectId/stories
GET    /api/stories/:id
PUT    /api/stories/:id
DELETE /api/stories/:id
POST   /api/stories/:id/generate          // G√©n√©ration IA

// Export
POST   /api/export/pdf
POST   /api/export/json-ld
POST   /api/export/bibtex
POST   /api/export/iiif

// AI Services
POST   /api/ai/transcribe                 // OCR single
POST   /api/ai/transcribe-batch           // OCR batch
POST   /api/ai/describe-image             // Description visuelle
POST   /api/ai/extract-entities           // NER
POST   /api/ai/generate-story             // Narratif automatique
POST   /api/ai/suggest-hotspots           // D√©tection zones int√©r√™t
```

---

## 3. Fonctionnalit√©s D√©taill√©es

### 3.1 Module OCR/Transcription (de Journal de Guerre)

**Am√©liorations propos√©es** :

```typescript
// packages/ai-services/src/ocr.ts
import { z } from 'zod';

export const OCRConfigSchema = z.object({
  provider: z.enum(['tesseract', 'ollama', 'claude', 'google-vision']),
  model: z.string().optional(),
  language: z.enum(['fra', 'eng', 'deu', 'auto']).default('fra'),
  mode: z.enum(['printed', 'handwritten', 'mixed']).default('mixed'),
  preprocessing: z.object({
    deskew: z.boolean().default(true),
    denoise: z.boolean().default(true),
    binarize: z.boolean().default(false),
    splitQuadrants: z.boolean().default(false), // H√©rit√© de Journal de Guerre
  }).default({}),
  postprocessing: z.object({
    spellcheck: z.boolean().default(true),
    deduplicate: z.boolean().default(true),
    structureDetection: z.boolean().default(true), // Paragraphes, listes
  }).default({}),
});

export interface OCRService {
  transcribe(imagePath: string, config: OCRConfig): Promise<TranscriptionResult>;
  transcribeBatch(imagePaths: string[], config: OCRConfig): Promise<TranscriptionResult[]>;
  estimateCost(imagePaths: string[], provider: string): Promise<CostEstimate>;
}

export interface TranscriptionResult {
  text: string;
  confidence: number;
  blocks: TextBlock[];
  metadata: {
    provider: string;
    duration: number;
    cost?: number;
  };
}

export interface TextBlock {
  text: string;
  boundingBox: { x: number; y: number; width: number; height: number };
  confidence: number;
  type: 'paragraph' | 'line' | 'word';
}
```

**Workflow OCR** :

1. Upload document ‚Üí Queue job
2. Preprocessing (deskew, denoise, split si n√©cessaire)
3. Envoi au provider (Tesseract local / Claude cloud)
4. Post-processing (correction, structure)
5. Extraction d'entit√©s automatique
6. G√©n√©ration embeddings
7. Indexation recherche
8. Notification utilisateur

### 3.2 Module Galerie Interactive (de Opale)

**Composant Gallery enrichi** :

```typescript
// apps/web/components/gallery/Gallery.tsx
'use client';

import { useState, useCallback, useMemo } from 'react';
import { useInfiniteQuery } from '@tanstack/react-query';
import { motion, AnimatePresence } from 'framer-motion';
import { useDebounce } from '@/hooks/useDebounce';
import { DocumentCard } from './DocumentCard';
import { FilterPanel } from './FilterPanel';
import { SearchBar } from './SearchBar';
import { ViewToggle } from './ViewToggle';

interface GalleryProps {
  projectId: string;
  initialFilters?: FilterOptions;
}

export function Gallery({ projectId, initialFilters }: GalleryProps) {
  const [searchQuery, setSearchQuery] = useState('');
  const [filters, setFilters] = useState<FilterOptions>(initialFilters || {});
  const [viewMode, setViewMode] = useState<'grid' | 'list' | 'masonry'>('masonry');
  const [searchMode, setSearchMode] = useState<'text' | 'semantic' | 'hybrid'>('hybrid');

  const debouncedQuery = useDebounce(searchQuery, 300);

  const {
    data,
    fetchNextPage,
    hasNextPage,
    isFetchingNextPage,
    isLoading,
  } = useInfiniteQuery({
    queryKey: ['documents', projectId, debouncedQuery, filters, searchMode],
    queryFn: async ({ pageParam = 0 }) => {
      const response = await fetch('/api/search', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          query: debouncedQuery,
          projectId,
          filters,
          mode: searchMode,
          limit: 20,
          offset: pageParam,
        }),
      });
      return response.json();
    },
    getNextPageParam: (lastPage, pages) => {
      if (lastPage.documents.length < 20) return undefined;
      return pages.length * 20;
    },
    initialPageParam: 0,
  });

  const documents = useMemo(() =>
    data?.pages.flatMap(page => page.documents) || [],
    [data]
  );

  // Intersection Observer pour infinite scroll
  const observerRef = useInfiniteScrollObserver(fetchNextPage, hasNextPage);

  return (
    <div className="flex flex-col lg:flex-row gap-6">
      {/* Panneau de filtres */}
      <aside className="w-full lg:w-64 shrink-0">
        <FilterPanel
          filters={filters}
          onFiltersChange={setFilters}
          projectId={projectId}
        />
      </aside>

      {/* Zone principale */}
      <main className="flex-1">
        {/* Barre de recherche */}
        <div className="mb-6 flex items-center gap-4">
          <SearchBar
            value={searchQuery}
            onChange={setSearchQuery}
            placeholder="Recherche s√©mantique..."
          />
          <ViewToggle mode={viewMode} onChange={setViewMode} />
          <SearchModeToggle mode={searchMode} onChange={setSearchMode} />
        </div>

        {/* R√©sultats */}
        <AnimatePresence mode="popLayout">
          <motion.div
            className={cn(
              viewMode === 'masonry' && 'columns-1 md:columns-2 lg:columns-3 gap-4',
              viewMode === 'grid' && 'grid grid-cols-1 md:grid-cols-3 lg:grid-cols-4 gap-4',
              viewMode === 'list' && 'flex flex-col gap-2'
            )}
          >
            {documents.map((doc) => (
              <motion.div
                key={doc.id}
                layout
                initial={{ opacity: 0, scale: 0.9 }}
                animate={{ opacity: 1, scale: 1 }}
                exit={{ opacity: 0, scale: 0.9 }}
              >
                <DocumentCard
                  document={doc}
                  viewMode={viewMode}
                  onAnnotate={() => openAnnotationEditor(doc)}
                  onViewHotspots={() => openStoryMode(doc)}
                />
              </motion.div>
            ))}
          </motion.div>
        </AnimatePresence>

        {/* Infinite scroll trigger */}
        <div ref={observerRef} className="h-10 mt-4">
          {isFetchingNextPage && <Spinner />}
        </div>
      </main>
    </div>
  );
}
```

### 3.3 Module Annotations Collaboratives (NOUVEAU)

```typescript
// apps/web/components/annotations/AnnotationEditor.tsx
'use client';

import { useState, useRef } from 'react';
import { Stage, Layer, Rect, Circle, Text } from 'react-konva';
import { motion } from 'framer-motion';
import { useAnnotations } from '@/hooks/useAnnotations';

interface AnnotationEditorProps {
  document: Document;
  onSave: (annotations: Annotation[]) => void;
}

export function AnnotationEditor({ document, onSave }: AnnotationEditorProps) {
  const [tool, setTool] = useState<'select' | 'region' | 'hotspot' | 'note'>('select');
  const [selectedAnnotation, setSelectedAnnotation] = useState<string | null>(null);
  const stageRef = useRef(null);

  const { annotations, addAnnotation, updateAnnotation, deleteAnnotation } = useAnnotations(document.id);

  const handleStageClick = (e: any) => {
    if (tool === 'select') return;

    const stage = e.target.getStage();
    const pos = stage.getPointerPosition();
    const scale = stage.scaleX();

    if (tool === 'hotspot') {
      addAnnotation({
        type: 'hotspot',
        x: pos.x / scale,
        y: pos.y / scale,
        content: '',
        metadata: { color: '#3B82F6' },
      });
    } else if (tool === 'region') {
      // D√©marrer le trac√© de r√©gion
      startRegionDraw(pos);
    } else if (tool === 'note') {
      addAnnotation({
        type: 'note',
        x: pos.x / scale,
        y: pos.y / scale,
        content: '',
        metadata: {},
      });
    }
  };

  return (
    <div className="flex h-full">
      {/* Toolbar */}
      <aside className="w-16 bg-gray-100 p-2 flex flex-col gap-2">
        <ToolButton icon="cursor" tool="select" current={tool} onClick={setTool} />
        <ToolButton icon="circle" tool="hotspot" current={tool} onClick={setTool} />
        <ToolButton icon="square" tool="region" current={tool} onClick={setTool} />
        <ToolButton icon="sticky-note" tool="note" current={tool} onClick={setTool} />
      </aside>

      {/* Canvas */}
      <div className="flex-1 relative overflow-hidden">
        <Stage
          ref={stageRef}
          width={window.innerWidth - 400}
          height={window.innerHeight}
          onClick={handleStageClick}
          draggable={tool === 'select'}
        >
          <Layer>
            {/* Image de fond */}
            <KonvaImage src={document.filePath} />

            {/* Annotations */}
            {annotations.map((annotation) => (
              <AnnotationShape
                key={annotation.id}
                annotation={annotation}
                isSelected={selectedAnnotation === annotation.id}
                onSelect={() => setSelectedAnnotation(annotation.id)}
                onChange={(updates) => updateAnnotation(annotation.id, updates)}
              />
            ))}
          </Layer>
        </Stage>
      </div>

      {/* Panneau de propri√©t√©s */}
      <aside className="w-80 bg-white border-l p-4">
        {selectedAnnotation ? (
          <AnnotationProperties
            annotation={annotations.find(a => a.id === selectedAnnotation)!}
            onUpdate={(updates) => updateAnnotation(selectedAnnotation, updates)}
            onDelete={() => deleteAnnotation(selectedAnnotation)}
            onLinkEntity={(entityId) => linkAnnotationToEntity(selectedAnnotation, entityId)}
          />
        ) : (
          <div className="text-gray-500">
            S√©lectionnez une annotation ou cr√©ez-en une nouvelle
          </div>
        )}
      </aside>
    </div>
  );
}
```

### 3.4 Module Ontologie/Graphe (de Journal de Guerre, am√©lior√©)

```typescript
// packages/ontology-engine/src/extractor.ts
import { OpenAI } from 'openai';
import nlp from 'compromise';
import { pipeline } from '@xenova/transformers';

export class OntologyExtractor {
  private nerPipeline: any;
  private llmClient: OpenAI;

  async initialize() {
    // Pipeline NER local (sentence-transformers)
    this.nerPipeline = await pipeline('ner', 'Xenova/bert-base-NER');
  }

  async extractEntities(text: string): Promise<ExtractedEntity[]> {
    const entities: ExtractedEntity[] = [];

    // 1. NER avec mod√®le local
    const nerResults = await this.nerPipeline(text);
    for (const result of nerResults) {
      entities.push({
        text: result.word,
        type: this.mapNERType(result.entity),
        start: result.start,
        end: result.end,
        confidence: result.score,
      });
    }

    // 2. Extraction linguistique (compromise.js)
    const doc = nlp(text);

    // Personnes
    doc.people().forEach((person) => {
      entities.push({
        text: person.text(),
        type: 'person',
        confidence: 0.8,
      });
    });

    // Lieux
    doc.places().forEach((place) => {
      entities.push({
        text: place.text(),
        type: 'place',
        confidence: 0.8,
      });
    });

    // Dates
    doc.dates().forEach((date) => {
      entities.push({
        text: date.text(),
        type: 'date',
        confidence: 0.9,
      });
    });

    // 3. D√©duplication et consolidation
    return this.consolidateEntities(entities);
  }

  async extractRelationships(
    text: string,
    entities: Entity[]
  ): Promise<EntityRelationship[]> {
    // Utilisation LLM pour extraction de relations complexes
    const prompt = `
      Texte: "${text}"

      Entit√©s identifi√©es: ${entities.map(e => `${e.name} (${e.type})`).join(', ')}

      Extrais les relations s√©mantiques entre ces entit√©s sous forme de triplets (sujet, relation, objet).
      Relations possibles: is_part_of, created_by, located_in, occurred_at, related_to, similar_to

      Format JSON:
      [
        { "source": "...", "relation": "...", "target": "...", "confidence": 0.9 }
      ]
    `;

    const response = await this.llmClient.chat.completions.create({
      model: 'gpt-4',
      messages: [{ role: 'user', content: prompt }],
      response_format: { type: 'json_object' },
    });

    return JSON.parse(response.choices[0].message.content);
  }

  async buildKnowledgeGraph(
    documents: Document[]
  ): Promise<KnowledgeGraph> {
    const graph: KnowledgeGraph = {
      nodes: [],
      edges: [],
    };

    for (const doc of documents) {
      if (!doc.transcription) continue;

      // Extraction d'entit√©s
      const extractedEntities = await this.extractEntities(doc.transcription);

      // Ajout au graphe avec r√©f√©rences documents
      for (const entity of extractedEntities) {
        const existingNode = graph.nodes.find(
          n => n.name === entity.text && n.type === entity.type
        );

        if (existingNode) {
          existingNode.documentRefs.push(doc.id);
          existingNode.mentionCount++;
        } else {
          graph.nodes.push({
            id: generateId(),
            name: entity.text,
            type: entity.type,
            documentRefs: [doc.id],
            mentionCount: 1,
          });
        }
      }

      // Extraction de relations
      const relationships = await this.extractRelationships(
        doc.transcription,
        graph.nodes
      );

      graph.edges.push(...relationships.map(r => ({
        ...r,
        documentRef: doc.id,
      })));
    }

    return graph;
  }
}
```

### 3.5 Module Recherche Hybride (NOUVEAU - combinant les deux)

```typescript
// packages/search-engine/src/hybrid-search.ts
import { MeiliSearch } from 'meilisearch';
import { PostgresClient } from './postgres';

export class HybridSearchEngine {
  private meilisearch: MeiliSearch;
  private postgres: PostgresClient;

  async search(query: SearchQuery): Promise<SearchResults> {
    const { query: searchText, mode, filters, limit, offset } = query;

    if (mode === 'text') {
      return this.textSearch(searchText, filters, limit, offset);
    } else if (mode === 'semantic') {
      return this.semanticSearch(searchText, filters, limit, offset);
    } else {
      // Hybrid: combine les deux avec pond√©ration
      return this.hybridSearch(searchText, filters, limit, offset);
    }
  }

  private async textSearch(
    query: string,
    filters: FilterOptions,
    limit: number,
    offset: number
  ): Promise<SearchResults> {
    // Meilisearch pour recherche full-text rapide
    const results = await this.meilisearch.index('documents').search(query, {
      limit,
      offset,
      filter: this.buildMeilisearchFilters(filters),
      attributesToSearchOn: ['title', 'transcription', 'tags', 'historicalContext'],
    });

    return {
      documents: results.hits,
      total: results.estimatedTotalHits,
      processingTime: results.processingTimeMs,
    };
  }

  private async semanticSearch(
    query: string,
    filters: FilterOptions,
    limit: number,
    offset: number
  ): Promise<SearchResults> {
    // G√©n√©ration embedding de la requ√™te
    const queryEmbedding = await this.generateEmbedding(query);

    // Recherche vectorielle avec pgvector
    const sql = `
      SELECT
        d.*,
        1 - (d.embedding <=> $1) as similarity
      FROM documents d
      WHERE d.project_id = $2
        ${this.buildSQLFilters(filters)}
      ORDER BY d.embedding <=> $1
      LIMIT $3 OFFSET $4
    `;

    const results = await this.postgres.query(sql, [
      queryEmbedding,
      filters.projectId,
      limit,
      offset,
    ]);

    return {
      documents: results.rows,
      total: results.rowCount,
      processingTime: results.duration,
    };
  }

  private async hybridSearch(
    query: string,
    filters: FilterOptions,
    limit: number,
    offset: number
  ): Promise<SearchResults> {
    // Recherches parall√®les
    const [textResults, semanticResults] = await Promise.all([
      this.textSearch(query, filters, limit * 2, 0),
      this.semanticSearch(query, filters, limit * 2, 0),
    ]);

    // Reciprocal Rank Fusion (RRF)
    const k = 60; // Constante RRF
    const scores = new Map<string, number>();

    textResults.documents.forEach((doc, index) => {
      const score = 1 / (k + index + 1);
      scores.set(doc.id, (scores.get(doc.id) || 0) + score * 0.4);
    });

    semanticResults.documents.forEach((doc, index) => {
      const score = 1 / (k + index + 1);
      scores.set(doc.id, (scores.get(doc.id) || 0) + score * 0.6);
    });

    // Tri par score fusionn√©
    const sortedIds = Array.from(scores.entries())
      .sort((a, b) => b[1] - a[1])
      .slice(offset, offset + limit)
      .map(([id]) => id);

    // R√©cup√©ration des documents complets
    const documents = await this.getDocumentsByIds(sortedIds);

    return {
      documents,
      total: scores.size,
      processingTime: Date.now(),
    };
  }

  private async generateEmbedding(text: string): Promise<number[]> {
    // sentence-transformers multilingual
    const response = await fetch('/api/ai/embed', {
      method: 'POST',
      body: JSON.stringify({ text }),
    });
    return response.json();
  }
}
```

### 3.6 Module Export (NOUVEAU)

```typescript
// apps/workers/export-worker/src/exporters.ts

export class PDFExporter {
  async exportProject(projectId: string, options: PDFOptions): Promise<Buffer> {
    const project = await getProject(projectId);
    const documents = await getProjectDocuments(projectId);

    const pdfDoc = await PDFDocument.create();

    // Page de titre
    const titlePage = pdfDoc.addPage();
    titlePage.drawText(project.name, { size: 24, font: 'Times-Bold' });

    // Table des mati√®res
    const tocPage = pdfDoc.addPage();
    // ...

    // Pages de documents
    for (const doc of documents) {
      const page = pdfDoc.addPage();

      // Image
      const image = await pdfDoc.embedJpg(await readFile(doc.filePath));
      page.drawImage(image, { x: 50, y: 400, width: 500 });

      // Transcription
      if (doc.transcription) {
        page.drawText(doc.transcription, { x: 50, y: 350, size: 10 });
      }

      // M√©tadonn√©es
      page.drawText(`Cat√©gorie: ${doc.category}`, { x: 50, y: 100 });
      page.drawText(`P√©riode: ${doc.period}`, { x: 50, y: 85 });

      // Annotations
      const annotations = await getDocumentAnnotations(doc.id);
      // ...
    }

    return pdfDoc.save();
  }
}

export class JSONLDExporter {
  async exportProject(projectId: string): Promise<object> {
    const project = await getProject(projectId);
    const documents = await getProjectDocuments(projectId);
    const entities = await getProjectEntities(projectId);

    return {
      '@context': 'https://schema.org',
      '@type': 'Collection',
      name: project.name,
      description: project.description,
      hasPart: documents.map(doc => ({
        '@type': doc.type === 'image' ? 'Photograph' : 'DigitalDocument',
        '@id': `${BASE_URL}/documents/${doc.id}`,
        name: doc.title,
        dateCreated: doc.period,
        description: doc.historicalContext,
        keywords: doc.tags,
        // Linked Open Data
        about: entities
          .filter(e => doc.entityIds.includes(e.id))
          .map(e => ({
            '@type': this.mapEntityType(e.type),
            name: e.name,
          })),
      })),
    };
  }
}

export class IIIFExporter {
  // Export compatible IIIF pour interop√©rabilit√© mus√©ale
  async exportManifest(projectId: string): Promise<IIIFManifest> {
    // ...
  }
}
```

### 3.7 Ontologie Progressive (INNOVATION MAJEURE)

L'ontologie n'est pas statique mais **√©volue dans le temps** avec versioning complet et tra√ßabilit√© des enrichissements.

**Concept cl√©** : Chaque modification de l'ontologie est versionn√©e, permettant de voir comment la compr√©hension du corpus a √©volu√©.

```typescript
// packages/ontology-engine/src/progressive-ontology.ts

// Schema de versioning ontologique
export interface OntologyVersion {
  id: string;
  projectId: string;
  versionNumber: number;
  createdAt: Date;
  createdBy: string;
  changeType: 'entity_added' | 'entity_modified' | 'entity_removed' |
              'relation_added' | 'relation_modified' | 'relation_removed' |
              'merge' | 'split' | 'reclassification';
  description: string;
  previousVersionId?: string;
  snapshot: OntologySnapshot;
}

export interface OntologySnapshot {
  entities: Entity[];
  relationships: EntityRelationship[];
  statistics: OntologyStats;
}

export interface OntologyStats {
  totalEntities: number;
  entitiesByType: Record<string, number>;
  totalRelationships: number;
  relationshipsByType: Record<string, number>;
  avgEntityMentions: number;
  graphDensity: number;
  clusteringCoefficient: number;
}

export class ProgressiveOntologyManager {
  private db: DatabaseClient;
  private aiService: AIService;

  /**
   * Phase 1: Extraction initiale automatique
   * Lors de l'import de nouveaux documents
   */
  async initialExtraction(documents: Document[]): Promise<OntologyVersion> {
    const entities: Entity[] = [];
    const relationships: EntityRelationship[] = [];

    for (const doc of documents) {
      // NER automatique
      const extractedEntities = await this.extractEntitiesNLP(doc.transcription);

      // R√©solution d'entit√©s (√©viter les doublons)
      for (const entity of extractedEntities) {
        const existingEntity = await this.findSimilarEntity(entity);
        if (existingEntity) {
          // Ajouter comme alias ou fusionner
          await this.mergeEntities(existingEntity, entity, doc.id);
        } else {
          entities.push(entity);
        }
      }

      // Extraction de relations basiques
      const docRelations = await this.extractBasicRelations(doc, entities);
      relationships.push(...docRelations);
    }

    return this.createVersion('initial_extraction', entities, relationships);
  }

  /**
   * Phase 2: Enrichissement progressif par l'utilisateur
   * Via l'interface Studio
   */
  async userEnrichment(
    entityId: string,
    enrichmentData: EntityEnrichment,
    userId: string
  ): Promise<OntologyVersion> {
    const entity = await this.getEntity(entityId);

    const enrichedEntity = {
      ...entity,
      ...enrichmentData,
      metadata: {
        ...entity.metadata,
        lastEnrichedBy: userId,
        lastEnrichedAt: new Date(),
        enrichmentHistory: [
          ...(entity.metadata.enrichmentHistory || []),
          {
            date: new Date(),
            userId,
            changes: enrichmentData,
          },
        ],
      },
    };

    await this.updateEntity(enrichedEntity);

    // Propager les changements aux relations
    await this.propagateChanges(entityId);

    return this.createVersion('user_enrichment', [enrichedEntity], []);
  }

  /**
   * Phase 3: Suggestion IA de nouvelles relations
   * Bas√© sur l'analyse s√©mantique du corpus
   */
  async suggestNewRelations(): Promise<RelationSuggestion[]> {
    const suggestions: RelationSuggestion[] = [];
    const entities = await this.getAllEntities();

    // Analyse de co-occurrence
    const coOccurrences = await this.analyzeCoOccurrences();

    for (const [pair, frequency] of coOccurrences) {
      if (frequency > 3 && !await this.relationExists(pair[0], pair[1])) {
        // Demander √† l'IA de qualifier la relation
        const suggestedRelation = await this.aiService.suggestRelationType(
          entities.find(e => e.id === pair[0])!,
          entities.find(e => e.id === pair[1])!,
          await this.getCoOccurrenceContexts(pair)
        );

        suggestions.push({
          sourceId: pair[0],
          targetId: pair[1],
          suggestedType: suggestedRelation.type,
          confidence: suggestedRelation.confidence,
          evidence: suggestedRelation.contexts,
        });
      }
    }

    // Analyse de similarit√© s√©mantique
    const semanticSuggestions = await this.findSemanticRelations(entities);
    suggestions.push(...semanticSuggestions);

    return suggestions.sort((a, b) => b.confidence - a.confidence);
  }

  /**
   * Phase 4: √âvolution temporelle de l'ontologie
   * Visualiser comment les concepts √©voluent
   */
  async getOntologyTimeline(projectId: string): Promise<OntologyTimeline> {
    const versions = await this.getAllVersions(projectId);

    return {
      versions: versions.map(v => ({
        id: v.id,
        date: v.createdAt,
        changeType: v.changeType,
        description: v.description,
        stats: v.snapshot.statistics,
      })),
      growthCurve: this.calculateGrowthCurve(versions),
      significantEvents: this.identifySignificantChanges(versions),
    };
  }

  /**
   * Phase 5: Comparaison de versions
   * Voir les diff√©rences entre deux snapshots
   */
  async compareVersions(
    versionA: string,
    versionB: string
  ): Promise<OntologyDiff> {
    const snapshotA = await this.getVersionSnapshot(versionA);
    const snapshotB = await this.getVersionSnapshot(versionB);

    return {
      addedEntities: this.findAddedEntities(snapshotA, snapshotB),
      removedEntities: this.findRemovedEntities(snapshotA, snapshotB),
      modifiedEntities: this.findModifiedEntities(snapshotA, snapshotB),
      addedRelations: this.findAddedRelations(snapshotA, snapshotB),
      removedRelations: this.findRemovedRelations(snapshotA, snapshotB),
      statisticsDiff: this.compareStatistics(
        snapshotA.statistics,
        snapshotB.statistics
      ),
    };
  }

  /**
   * Phase 6: Fusion intelligente
   * Combiner les contributions de plusieurs utilisateurs
   */
  async mergeContributions(
    contributionIds: string[]
  ): Promise<OntologyVersion> {
    const contributions = await Promise.all(
      contributionIds.map(id => this.getContribution(id))
    );

    // D√©tection de conflits
    const conflicts = this.detectConflicts(contributions);

    if (conflicts.length > 0) {
      // R√©solution automatique ou manuelle selon la gravit√©
      for (const conflict of conflicts) {
        if (conflict.autoResolvable) {
          await this.autoResolveConflict(conflict);
        } else {
          await this.flagForManualReview(conflict);
        }
      }
    }

    // Fusionner les changements non-conflictuels
    const mergedChanges = this.mergeNonConflicting(contributions);

    return this.createVersion('merge', mergedChanges.entities, mergedChanges.relations);
  }
}

// Sch√©ma de base de donn√©es pour le versioning
/*
CREATE TABLE ontology_versions (
  id UUID PRIMARY KEY,
  project_id UUID REFERENCES projects(id),
  version_number INTEGER NOT NULL,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  created_by UUID REFERENCES users(id),
  change_type VARCHAR(50) NOT NULL,
  description TEXT,
  previous_version_id UUID REFERENCES ontology_versions(id),
  snapshot JSONB NOT NULL,
  UNIQUE(project_id, version_number)
);

CREATE TABLE entity_history (
  id UUID PRIMARY KEY,
  entity_id UUID REFERENCES entities(id),
  version_id UUID REFERENCES ontology_versions(id),
  change_type VARCHAR(50) NOT NULL,
  old_value JSONB,
  new_value JSONB,
  changed_by UUID REFERENCES users(id),
  changed_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_versions_project ON ontology_versions(project_id, version_number DESC);
CREATE INDEX idx_entity_history ON entity_history(entity_id, changed_at DESC);
*/
```

### 3.8 G√©n√©ration de Contenu IA (INNOVATION MAJEURE)

Moteur de g√©n√©ration automatique de contenus √©ditoriaux bas√© sur l'analyse de l'archive.

**Types de contenu g√©n√©r√©s** :
1. **Synth√®ses documentaires** - R√©sum√©s de collections
2. **Descriptions contextuelles** - Contexte historique enrichi
3. **Narratifs th√©matiques** - Stories automatiques
4. **R√©ponses aux questions** - Q&A sur le corpus
5. **M√©tadonn√©es enrichies** - Tags, cat√©gories, p√©riodes
6. **Transcriptions am√©lior√©es** - Correction et structuration

```typescript
// packages/ai-services/src/content-generator.ts

export class ContentGenerator {
  private llmClient: LLMClient;
  private ontology: ProgressiveOntologyManager;
  private vectorSearch: HybridSearchEngine;

  /**
   * G√©n√©ration de synth√®se documentaire
   * Cr√©e un r√©sum√© structur√© d'une collection de documents
   */
  async generateCollectionSummary(
    documentIds: string[],
    options: SummaryOptions
  ): Promise<GeneratedSummary> {
    const documents = await this.getDocuments(documentIds);
    const entities = await this.getRelatedEntities(documentIds);
    const relationships = await this.getRelationships(entities.map(e => e.id));

    const prompt = `
      Tu es un historien sp√©cialis√© dans l'analyse de documents patrimoniaux.

      DOCUMENTS (${documents.length} √©l√©ments):
      ${documents.map(d => `
        - Titre: ${d.title}
        - P√©riode: ${d.period}
        - Transcription: ${d.transcription?.substring(0, 500)}...
        - Contexte: ${d.historicalContext}
      `).join('\n')}

      ENTIT√âS IDENTIFI√âES:
      ${entities.map(e => `- ${e.name} (${e.type}): ${e.description}`).join('\n')}

      RELATIONS:
      ${relationships.map(r => `- ${r.source} --[${r.type}]--> ${r.target}`).join('\n')}

      G√©n√®re une synth√®se structur√©e comprenant:
      1. Vue d'ensemble (3-5 phrases)
      2. Th√®mes principaux identifi√©s
      3. Personnages cl√©s et leurs r√¥les
      4. Chronologie des √©v√©nements
      5. Lieux mentionn√©s et leur importance
      6. Observations historiographiques
      7. Questions ouvertes pour recherche future

      Style: acad√©mique mais accessible
      Longueur: ${options.length || 'medium'}
      Langue: ${options.language || 'fr'}
    `;

    const response = await this.llmClient.generate(prompt, {
      model: options.model || 'claude-3-sonnet',
      temperature: 0.3,
      maxTokens: options.maxTokens || 2000,
    });

    return {
      content: response.text,
      metadata: {
        generatedAt: new Date(),
        model: options.model,
        documentCount: documents.length,
        entityCount: entities.length,
        confidence: this.calculateConfidence(response),
      },
      sections: this.parseSections(response.text),
    };
  }

  /**
   * G√©n√©ration de description contextuelle pour une image/document
   * Enrichit automatiquement les m√©tadonn√©es
   */
  async generateContextualDescription(
    documentId: string
  ): Promise<EnrichedDescription> {
    const document = await this.getDocument(documentId);
    const similarDocs = await this.vectorSearch.findSimilar(documentId, 5);
    const entities = await this.getDocumentEntities(documentId);
    const historicalContext = await this.getRelevantHistoricalContext(document);

    const prompt = `
      DOCUMENT PRINCIPAL:
      - Type: ${document.type}
      - Titre actuel: ${document.title}
      - P√©riode: ${document.period}
      - Tags existants: ${document.tags.join(', ')}
      ${document.transcription ? `- Transcription: ${document.transcription}` : ''}

      DOCUMENTS SIMILAIRES:
      ${similarDocs.map(d => `- ${d.title} (similarit√©: ${d.similarity})`).join('\n')}

      ENTIT√âS LI√âES:
      ${entities.map(e => `- ${e.name} (${e.type})`).join('\n')}

      CONTEXTE HISTORIQUE:
      ${historicalContext}

      G√©n√®re:
      1. Une description enrichie (2-3 paragraphes) contextualisant ce document
      2. Des tags additionnels pertinents (5-10)
      3. Une p√©riode plus pr√©cise si possible
      4. Des liens th√©matiques avec d'autres documents
      5. Des questions que ce document soul√®ve
      6. Son importance historique

      Format: JSON structur√©
    `;

    const response = await this.llmClient.generate(prompt, {
      model: 'claude-3-sonnet',
      temperature: 0.2,
      responseFormat: 'json',
    });

    return JSON.parse(response.text);
  }

  /**
   * G√©n√©ration automatique de Story/Narratif
   * Cr√©e un parcours narratif √† partir de documents
   */
  async generateStory(
    themeOrQuery: string,
    projectId: string,
    options: StoryOptions
  ): Promise<GeneratedStory> {
    // Recherche s√©mantique des documents pertinents
    const relevantDocs = await this.vectorSearch.search({
      query: themeOrQuery,
      projectId,
      mode: 'semantic',
      limit: options.maxDocuments || 20,
    });

    // Analyse du fil narratif potentiel
    const narrativeStructure = await this.analyzeNarrativeStructure(
      relevantDocs.documents
    );

    const prompt = `
      Tu es un m√©diateur culturel expert en narration patrimoniale.

      TH√àME: "${themeOrQuery}"

      DOCUMENTS DISPONIBLES (${relevantDocs.documents.length}):
      ${relevantDocs.documents.map((d, i) => `
        ${i + 1}. ${d.title}
        - ID: ${d.id}
        - P√©riode: ${d.period}
        - R√©sum√©: ${d.description}
        - Entit√©s: ${d.entities?.join(', ')}
      `).join('\n')}

      STRUCTURE NARRATIVE SUGG√âR√âE:
      ${JSON.stringify(narrativeStructure, null, 2)}

      Cr√©e un parcours narratif comprenant:
      1. Titre accrocheur de la story
      2. Introduction captivante (3-4 phrases)
      3. S√©quence ordonn√©e de documents avec:
         - Transition narrative entre chaque document
         - Points d'int√©r√™t √† mettre en valeur (hotspots sugg√©r√©s)
         - Questions √† poser au visiteur
      4. Conclusion et ouverture
      5. Pour chaque document, sugg√®re:
         - Dur√©e de consultation recommand√©e
         - √âl√©ments visuels √† mettre en avant
         - Liens avec les autres documents

      Style: ${options.tone || 'engaging'} (engaging, academic, accessible, dramatic)
      Public cible: ${options.audience || 'general'}
      Dur√©e estim√©e: ${options.duration || '10 minutes'}

      Format: JSON structur√© pour int√©gration directe
    `;

    const response = await this.llmClient.generate(prompt, {
      model: 'claude-3-opus',
      temperature: 0.5,
      maxTokens: 4000,
      responseFormat: 'json',
    });

    const storyData = JSON.parse(response.text);

    // Enrichir avec des hotspots IA-sugg√©r√©s
    for (const item of storyData.sequence) {
      const suggestedHotspots = await this.suggestHotspots(item.documentId);
      item.suggestedHotspots = suggestedHotspots;
    }

    return {
      id: generateId(),
      title: storyData.title,
      theme: themeOrQuery,
      introduction: storyData.introduction,
      sequence: storyData.sequence,
      conclusion: storyData.conclusion,
      metadata: {
        generatedAt: new Date(),
        model: 'claude-3-opus',
        documentCount: relevantDocs.documents.length,
        estimatedDuration: storyData.estimatedDuration,
      },
      status: 'draft', // N√©cessite validation humaine
    };
  }

  /**
   * Moteur de Questions/R√©ponses sur le corpus
   * RAG (Retrieval Augmented Generation) pour r√©pondre aux questions
   */
  async answerQuestion(
    question: string,
    projectId: string
  ): Promise<AnswerResult> {
    // R√©cup√©ration des documents pertinents
    const relevantDocs = await this.vectorSearch.search({
      query: question,
      projectId,
      mode: 'hybrid',
      limit: 10,
    });

    // R√©cup√©ration des entit√©s pertinentes
    const relevantEntities = await this.searchEntities(question, projectId);

    const prompt = `
      Tu es un assistant de recherche sp√©cialis√© dans l'analyse de corpus patrimoniaux.

      QUESTION: "${question}"

      SOURCES DOCUMENTAIRES:
      ${relevantDocs.documents.map((d, i) => `
        [${i + 1}] ${d.title} (${d.period})
        ${d.transcription || d.description}
      `).join('\n\n')}

      ENTIT√âS CONNUES:
      ${relevantEntities.map(e => `- ${e.name}: ${e.description}`).join('\n')}

      R√©ponds √† la question en:
      1. Citant pr√©cis√©ment les sources (num√©ro entre crochets)
      2. Distinguant les faits √©tablis des hypoth√®ses
      3. Mentionnant les lacunes dans les sources si pertinent
      4. Sugg√©rant des pistes de recherche compl√©mentaires

      Format:
      - R√©ponse principale (2-3 paragraphes)
      - Sources cit√©es avec pertinence
      - Niveau de confiance (high/medium/low)
      - Questions connexes sugg√©r√©es
    `;

    const response = await this.llmClient.generate(prompt, {
      model: 'claude-3-sonnet',
      temperature: 0.1,
    });

    return {
      answer: this.parseAnswer(response.text),
      sources: relevantDocs.documents.map(d => ({
        id: d.id,
        title: d.title,
        relevanceScore: d.similarity,
      })),
      confidence: this.extractConfidence(response.text),
      relatedQuestions: this.extractRelatedQuestions(response.text),
      generatedAt: new Date(),
    };
  }

  /**
   * Am√©lioration automatique des transcriptions
   * Correction orthographique, structuration, normalisation
   */
  async improveTranscription(
    transcription: string,
    context: TranscriptionContext
  ): Promise<ImprovedTranscription> {
    const prompt = `
      Tu es un pal√©ographe expert en documents fran√ßais du ${context.period}.

      TRANSCRIPTION BRUTE:
      """
      ${transcription}
      """

      CONTEXTE:
      - Type de document: ${context.documentType}
      - P√©riode: ${context.period}
      - Auteur probable: ${context.author || 'Inconnu'}
      - Langue: ${context.language || 'Fran√ßais'}

      Am√©liore la transcription en:
      1. Corrigeant l'orthographe selon les conventions de l'√©poque
      2. Ajoutant la ponctuation manquante
      3. Structurant en paragraphes logiques
      4. Identifiant et balisantmarquant:
         - [illisible] pour les parties non d√©chiffrables
         - [incertain: ...] pour les lectures douteuses
         - [rature: ...] pour les passages ratur√©s
         - [ajout marginal: ...] pour les annotations
      5. Normalisant les abr√©viations courantes
      6. Pr√©servant les particularit√©s linguistiques significatives

      Fournis:
      - Transcription am√©lior√©e
      - Liste des corrections majeures
      - Notes pal√©ographiques
      - Niveau de confiance global
    `;

    const response = await this.llmClient.generate(prompt, {
      model: 'claude-3-sonnet',
      temperature: 0.1,
    });

    return this.parseImprovedTranscription(response.text);
  }

  /**
   * Suggestion automatique de hotspots sur une image
   * Utilise la vision IA pour identifier les zones d'int√©r√™t
   */
  async suggestHotspots(documentId: string): Promise<SuggestedHotspot[]> {
    const document = await this.getDocument(documentId);

    if (document.type !== 'image') {
      return [];
    }

    // Analyse visuelle de l'image
    const visualAnalysis = await this.llmClient.analyzeImage(document.filePath, {
      prompt: `
        Analyse cette image patrimoniale et identifie les zones d'int√©r√™t:
        - Personnes (visages, groupes)
        - Objets significatifs (outils, v√™tements, √©quipements)
        - √âl√©ments architecturaux ou paysagers
        - Textes ou inscriptions visibles
        - D√©tails techniques ou artistiques remarquables

        Pour chaque zone, fournis:
        - Position approximative (x%, y%)
        - Type d'√©l√©ment
        - Description
        - Importance (1-5)
        - Questions que cela soul√®ve

        Format: JSON array
      `,
      model: 'claude-3-sonnet',
    });

    return visualAnalysis.map((zone: any) => ({
      x: zone.x,
      y: zone.y,
      type: zone.type,
      label: zone.description,
      importance: zone.importance,
      suggestedQuestions: zone.questions,
      confidence: zone.confidence,
    }));
  }
}

// Types pour la g√©n√©ration de contenu
interface GeneratedSummary {
  content: string;
  metadata: GenerationMetadata;
  sections: {
    overview: string;
    themes: string[];
    characters: { name: string; role: string }[];
    timeline: { date: string; event: string }[];
    locations: { name: string; significance: string }[];
    observations: string[];
    openQuestions: string[];
  };
}

interface GeneratedStory {
  id: string;
  title: string;
  theme: string;
  introduction: string;
  sequence: {
    order: number;
    documentId: string;
    transition: string;
    focusPoints: string[];
    questions: string[];
    duration: number;
    suggestedHotspots?: SuggestedHotspot[];
  }[];
  conclusion: string;
  metadata: GenerationMetadata;
  status: 'draft' | 'published';
}

interface AnswerResult {
  answer: {
    mainResponse: string;
    facts: string[];
    hypotheses: string[];
    gaps: string[];
  };
  sources: { id: string; title: string; relevanceScore: number }[];
  confidence: 'high' | 'medium' | 'low';
  relatedQuestions: string[];
  generatedAt: Date;
}
```

### 3.9 Espaces de Travail D√©taill√©s

#### 3.9.1 WORKSPACE - Espace Travail sur l'Archive

```typescript
// apps/web/app/(auth)/workspace/page.tsx
'use client';

export default function WorkspacePage() {
  return (
    <WorkspaceLayout>
      {/* Pipeline d'import */}
      <ImportPipeline
        onUpload={handleFileUpload}
        supportedFormats={['jpg', 'png', 'tiff', 'pdf', 'heic']}
        batchProcessing={true}
      />

      {/* File d'attente OCR */}
      <OCRQueue
        jobs={pendingJobs}
        onRetry={retryJob}
        onCancel={cancelJob}
        showProgress={true}
      />

      {/* √âditeur de transcription */}
      <TranscriptionEditor
        document={selectedDocument}
        aiSuggestions={true}
        collaborativeEditing={true}
        versionHistory={true}
      />

      {/* Gestionnaire d'annotations */}
      <AnnotationManager
        tools={['hotspot', 'region', 'note', 'correction']}
        entityLinking={true}
        validation={true}
      />

      {/* √âditeur d'ontologie */}
      <OntologyEditor
        mode="progressive"
        aiSuggestions={true}
        conflictResolution={true}
        versioning={true}
      />

      {/* G√©n√©rateur de m√©tadonn√©es */}
      <MetadataGenerator
        autoTag={true}
        aiEnrichment={true}
        validation={true}
      />
    </WorkspaceLayout>
  );
}
```

**Fonctionnalit√©s cl√©s du WORKSPACE** :

1. **Import intelligent**
   - Drag & drop multiple
   - D√©tection automatique du type (manuscrit, imprim√©, photo)
   - Extraction de m√©tadonn√©es EXIF
   - Pr√©visualisation avant import

2. **OCR collaboratif**
   - Transcription c√¥te √† c√¥te (image + texte)
   - Suggestions IA en temps r√©el
   - Correction collaborative
   - Historique des modifications

3. **Enrichissement progressif**
   - Ajout incr√©mental de m√©tadonn√©es
   - Validation par pairs
   - Propagation des enrichissements
   - Score de compl√©tude

4. **Gestion de l'ontologie**
   - Cr√©ation/modification d'entit√©s
   - D√©finition de relations
   - Fusion d'entit√©s dupliqu√©es
   - Export/import de sch√©mas

#### 3.9.2 READER - Espace Lecture de l'Archive

```typescript
// apps/web/app/(public)/reader/page.tsx
'use client';

export default function ReaderPage() {
  return (
    <ReaderLayout>
      {/* Navigation multiple */}
      <NavigationModes>
        <GalleryView mode="masonry" />
        <TimelineView interactive={true} />
        <MapView clustering={true} />
        <ThematicPaths curated={true} />
      </NavigationModes>

      {/* Visualisation immersive */}
      <ImmersiveViewer
        zoom={{ min: 0.5, max: 5 }}
        hotspots={true}
        annotations={true}
        comparison={true}
      />

      {/* Mode Story */}
      <StoryMode
        autoplay={false}
        narration={true}
        relatedContent={true}
      />

      {/* Contextualization */}
      <ContextPanel
        historicalContext={true}
        relatedDocuments={true}
        entities={true}
        bibliography={true}
      />

      {/* Partage et export */}
      <ShareTools
        socialMedia={true}
        embed={true}
        citation={true}
        favorites={true}
      />
    </ReaderLayout>
  );
}
```

**Fonctionnalit√©s cl√©s du READER** :

1. **Navigation fluide**
   - Galerie responsive avec filtres dynamiques
   - Timeline interactive zoomable
   - Carte avec clusters g√©ographiques
   - Parcours th√©matiques guid√©s

2. **Consultation enrichie**
   - Zoom haute d√©finition
   - Hotspots interactifs
   - Transcription synchronis√©e
   - Contexte historique

3. **Exp√©rience narrative**
   - Stories immersives
   - Transitions anim√©es
   - Contenus connexes
   - Mode plein √©cran

4. **Accessibilit√©**
   - PWA offline
   - Mode sombre
   - Taille de texte ajustable
   - Lecteur d'√©cran compatible

#### 3.9.3 INSIGHT - Espace Compr√©hension de l'Archive

```typescript
// apps/web/app/(auth)/insight/page.tsx
'use client';

export default function InsightPage() {
  return (
    <InsightLayout>
      {/* Moteur de questions */}
      <QuestionAnswering
        naturalLanguage={true}
        citeSources={true}
        suggestFollowUp={true}
      />

      {/* Visualisation du graphe */}
      <KnowledgeGraphVisualization
        interactive={true}
        filtering={true}
        clustering={true}
        pathfinding={true}
      />

      {/* Analyse th√©matique */}
      <ThematicAnalysis
        topicModeling={true}
        trends={true}
        comparisons={true}
      />

      {/* G√©n√©ration de synth√®ses */}
      <SynthesisGenerator
        collections={true}
        themes={true}
        periods={true}
        entities={true}
      />

      {/* D√©tection de patterns */}
      <PatternDetection
        temporal={true}
        semantic={true}
        visual={true}
      />

      {/* Recommandations */}
      <RecommendationEngine
        similarDocuments={true}
        missingLinks={true}
        researchSuggestions={true}
      />

      {/* Exports analytiques */}
      <AnalyticsExport
        formats={['pdf', 'csv', 'json', 'graph']}
        customReports={true}
        visualizations={true}
      />
    </InsightLayout>
  );
}
```

**Fonctionnalit√©s cl√©s de l'INSIGHT** :

1. **Interrogation intelligente**
   - Questions en langage naturel
   - R√©ponses sourc√©es et contextualis√©es
   - Suggestions de questions connexes
   - Historique des requ√™tes

2. **Exploration du graphe**
   - Visualisation 3D interactive
   - Filtrage par type d'entit√©/relation
   - D√©tection de communaut√©s
   - Chemins entre entit√©s

3. **Analyses automatis√©es**
   - Topic modeling
   - Analyse de sentiment (pour textes)
   - D√©tection d'anomalies
   - √âvolution temporelle

4. **G√©n√©ration de rapports**
   - Synth√®ses automatiques
   - Rapports personnalis√©s
   - Visualisations exportables
   - Formats acad√©miques

---

## 4. Interface Utilisateur

### 4.1 Personas et Parcours

| Persona | Besoin Principal | Parcours Type |
|---------|-----------------|---------------|
| **Chercheur** | Analyser et annoter | Upload ‚Üí OCR ‚Üí Annotations ‚Üí Export acad√©mique |
| **Conservateur** | Pr√©server et documenter | Import ‚Üí M√©tadonn√©es ‚Üí Ontologie ‚Üí Publication |
| **Grand public** | D√©couvrir et explorer | Galerie ‚Üí Stories ‚Üí Timeline ‚Üí Partage |
| **Contributeur** | Enrichir collectivement | Connexion ‚Üí Transcription ‚Üí Validation ‚Üí Hotspots |

### 4.2 √âcrans Principaux

1. **Dashboard** - Vue d'ensemble du projet
2. **Galerie** - Navigation et recherche des documents
3. **Studio d'annotation** - √âditeur visuel riche
4. **Mode histoire** - Exploration narrative immersive
5. **Timeline** - Frise chronologique interactive
6. **Carte** - Visualisation g√©ographique
7. **Graphe d'ontologie** - Exploration des relations
8. **Recherche avanc√©e** - Filtres et requ√™tes complexes
9. **Exports** - G√©n√©ration de rapports et donn√©es
10. **Administration** - Gestion utilisateurs et projets

### 4.3 Design System

```typescript
// tailwind.config.ts
export default {
  theme: {
    extend: {
      colors: {
        // Palette inspir√©e d'Opale
        heritage: {
          50: '#FDF8F3',   // Cr√®me tr√®s l√©ger
          100: '#F5EBE0',
          200: '#E8D5C4',
          300: '#D4B896',
          400: '#C19A6B',
          500: '#A67B5B',  // Couleur principale
          600: '#8B6347',
          700: '#704F39',
          800: '#553D2E',
          900: '#3A2A1F',  // Brun tr√®s fonc√©
        },
        accent: {
          500: '#3B82F6',  // Bleu pour actions
        },
      },
      fontFamily: {
        serif: ['Georgia', 'Cambria', 'serif'],
        sans: ['Inter', 'system-ui', 'sans-serif'],
      },
    },
  },
};
```

---

## 5. Roadmap d'Impl√©mentation

### Phase 1 : Fondations (4-6 semaines)

- [ ] Setup monorepo (pnpm workspaces)
- [ ] Configuration Next.js 15 + TypeScript strict
- [ ] Schema base de donn√©es PostgreSQL + pgvector
- [ ] Authentification NextAuth.js
- [ ] API REST de base (CRUD documents)
- [ ] Upload et stockage fichiers (S3/R2)
- [ ] CI/CD pipeline (GitHub Actions)
- [ ] D√©ploiement initial (Vercel/Railway)

### Phase 2 : OCR et Transcription (3-4 semaines)

- [ ] Service OCR multi-provider
- [ ] Queue jobs asynchrones (BullMQ)
- [ ] Interface upload batch
- [ ] Pr√©processing images
- [ ] Postprocessing transcriptions
- [ ] Validation et corrections
- [ ] Dashboard de suivi jobs

### Phase 3 : Galerie Interactive (3-4 semaines)

- [ ] Composant Gallery avec filtres
- [ ] Recherche full-text (Meilisearch)
- [ ] Lazy loading et infinite scroll
- [ ] Mode plein √©cran avec zoom
- [ ] Responsive design
- [ ] Animations Framer Motion

### Phase 4 : Recherche S√©mantique (3-4 semaines)

- [ ] Service g√©n√©ration embeddings
- [ ] Index vectoriel pgvector
- [ ] API recherche hybride
- [ ] Interface recherche avanc√©e
- [ ] Suggestions automatiques
- [ ] Filtres complexes

### Phase 5 : Annotations et Hotspots (4-5 semaines)

- [ ] √âditeur visuel Konva.js
- [ ] Types d'annotations (note, r√©gion, hotspot)
- [ ] Sauvegarde temps r√©el
- [ ] Liaison avec entit√©s
- [ ] Permissions collaboratives
- [ ] Historique des modifications

### Phase 6 : Ontologie et NLP (3-4 semaines)

- [ ] Service extraction entit√©s (NER)
- [ ] Graphe de relations
- [ ] Interface d'√©dition ontologie
- [ ] Visualisation graphe (D3.js ou Sigma.js)
- [ ] Requ√™tes sur le graphe
- [ ] Export RDF/OWL

### Phase 7 : Mode Narratif (3-4 semaines)

- [ ] Composant StoryMode
- [ ] Carrousels d'images li√©es
- [ ] Panneaux d'information
- [ ] Cr√©ation de stories
- [ ] G√©n√©ration assist√©e par IA
- [ ] Publication et partage

### Phase 8 : PWA et Offline (2-3 semaines)

- [ ] Service Worker (Workbox)
- [ ] Manifest PWA
- [ ] Strat√©gies de cache
- [ ] Synchronisation offline
- [ ] Installation native
- [ ] Tests performance

### Phase 9 : Exports et Int√©grations (3-4 semaines)

- [ ] Export PDF structur√©
- [ ] Export JSON-LD (Linked Data)
- [ ] Export BibTeX
- [ ] Export IIIF manifest
- [ ] API publique document√©e
- [ ] Webhooks

### Phase 10 : Polish et Documentation (2-3 semaines)

- [ ] Tests E2E (Playwright)
- [ ] Optimisation performance
- [ ] Accessibilit√© (WCAG 2.1)
- [ ] Documentation utilisateur
- [ ] Documentation API
- [ ] Guides de contribution

**Dur√©e totale estim√©e : 30-41 semaines (7-10 mois)**

---

## 6. Consid√©rations Techniques

### 6.1 Performance

- **SSG pour pages statiques** : Pr√©-g√©n√©ration au build
- **ISR pour contenu dynamique** : Revalidation incr√©mentale
- **Edge caching** : CDN Vercel/Cloudflare
- **Lazy loading** : Images et composants
- **Code splitting** : Bundles optimis√©s
- **Service Worker** : Cache offline intelligent

### 6.2 Scalabilit√©

- **Base de donn√©es** : PostgreSQL avec read replicas
- **Stockage** : S3/R2 avec CDN
- **Jobs** : Redis + BullMQ (horizontal scaling)
- **Recherche** : Meilisearch cluster
- **API** : Edge functions serverless

### 6.3 S√©curit√©

- **Authentification** : OAuth 2.0 (Google, GitHub)
- **Autorisation** : RBAC (Admin, Editor, Contributor, Viewer)
- **Validation** : Zod schemas c√¥t√© client et serveur
- **Upload** : Validation MIME types, taille max, antivirus
- **API** : Rate limiting, CORS, CSRF protection
- **Donn√©es** : Chiffrement at-rest et in-transit

### 6.4 Monitoring

- **APM** : Vercel Analytics / New Relic
- **Logs** : Structured logging (Pino)
- **Errors** : Sentry integration
- **M√©triques** : Custom dashboards
- **Alerting** : Slack/Discord notifications

---

## 7. Budget et Ressources

### 7.1 √âquipe Id√©ale

| R√¥le | Temps | Comp√©tences Cl√©s |
|------|-------|-----------------|
| **Lead Dev Full-Stack** | 100% | Next.js, TypeScript, PostgreSQL, AI |
| **Frontend Developer** | 80% | React, Tailwind, Framer Motion, Konva |
| **Backend Developer** | 80% | Node.js, PostgreSQL, Redis, BullMQ |
| **ML/NLP Engineer** | 50% | Python, sentence-transformers, NER |
| **UX/UI Designer** | 50% | Figma, Design System, Accessibility |
| **DevOps** | 30% | Docker, CI/CD, Monitoring |

### 7.2 Infrastructure Mensuelle

| Service | Co√ªt Estim√© |
|---------|-------------|
| Vercel Pro | ~$20/mois |
| PostgreSQL (Supabase/Railway) | ~$25/mois |
| Redis (Upstash) | ~$10/mois |
| S3 Storage (R2) | ~$15/mois |
| Meilisearch Cloud | ~$29/mois |
| AI APIs (Claude/OpenAI) | ~$50-200/mois |
| **Total** | **~$150-300/mois** |

### 7.3 Co√ªts IA par Op√©ration

| Op√©ration | Provider | Co√ªt Estim√© |
|-----------|----------|-------------|
| OCR 1 page | Ollama (local) | $0 |
| OCR 1 page | Claude Vision | ~$0.02 |
| Embedding 1 doc | Local | $0 |
| NER extraction | Local | $0 |
| Story generation | GPT-4 | ~$0.10 |

---

## 8. Conclusion

Cette vision d'**Archivia** combine les forces compl√©mentaires des deux projets existants :

**De Journal de Guerre** :
- Pipeline OCR robuste multi-provider
- Extraction d'ontologie automatis√©e
- Recherche s√©mantique par embeddings
- Documentation m√©thodologique exemplaire

**D'Opale** :
- Architecture Next.js moderne et performante
- Galerie interactive avec animations fluides
- Mode narratif avec hotspots innovants
- PWA offline-first compl√®te

**Innovations ajout√©es** :
- Annotations collaboratives visuelles
- Recherche hybride (texte + vectorielle)
- Multi-projets et multi-tenant
- Exports acad√©miques (PDF, JSON-LD, BibTeX, IIIF)
- G√©n√©ration de contenu assist√©e par IA
- API REST compl√®te pour int√©grations

Le r√©sultat sera une **plateforme open-source de r√©f√©rence** pour la num√©risation, l'analyse et la valorisation du patrimoine culturel, combinant le meilleur des technologies modernes avec une exp√©rience utilisateur immersive et accessible.

---

*Document de vision r√©dig√© le 17 novembre 2025*
*Version 1.0*
